<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
 <meta name="description" content="Project page for the paper 'The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs'">
  <meta property="og:title" content="The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs">
  <meta property="og:description" content="Exploring dissociations between self-reported traits and actual behaviors in large language models — a study on LLM personality, alignment, and consistency.">
  <meta property="og:url" content="https://pengrui-han.github.io/LLM_Personality.github.io/">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/workflow.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="The Personality Illusion: Dissociation Between Self-Reports & Behavior in LLMs">
  <meta name="twitter:description" content="Project page for our paper exploring how LLMs reveal gaps between self-reported personality traits and actual behaviors.">
  <meta name="twitter:image" content="https://yourdomain.com/static/images/workflow.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="LLM, AI alignment, personality traits, behavioral consistency, machine learning, artificial intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior In LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/caltech.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="container is-widescreen">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">The Personality Illusion: Revealing Dissociation <br> Between Self-Reports & Behavior in LLMs</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://pengrui-han.github.io/" target="_blank">Pengrui Han</a><sup>* 1 2</sup>,</span>
                <span class="author-block">
                  <a href="https://rkocielnik.com/" target="_blank">Rafal Kocielnik</a><sup>* 1</sup>,</span>
                  <span class="author-block">
                    <a href="https://peiyang-song.github.io/" target="_blank">Peiyang Song</a><sup>1</sup>,</span>
                    <span class="author-block">
                    <a href="https://www.arct.cam.ac.uk/staff/dr-ramit-debnath" target="_blank">Ramit Debnath</a> <sup>3</sup>,</span>
                    <a href="https://www.hss.caltech.edu/people/dean-mobbs" target="_blank">Dean Mobbs</a><sup>1</sup>,</span>
                    <a href="https://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima Anandkumar</a><sup>1</sup>,</span>
                    <a href="https://www.hss.caltech.edu/people/r-michael-alvarez" target="_blank">R. Michael Alvarez</a><sup>1</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>California Institute of Technology; <sup>2</sup>University of Illinois Urbana-Champaign; <sup>3</sup>University of Cambridge  
                      <br><a href="https://icml.cc/virtual/2025/workshop/39954" target="_blank" rel="noopener noreferrer">ICML 2025 MoFA Workshop</a>; Under Conference Review </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                  </div>

                  

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2509.03730" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/psychology-of-AI/Personality-Illusion" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="static/images/workflow.png" 
           alt="Workflow illustration" 
           style="max-width: 100%; height: auto; display: block; margin: 0 auto;" />
      <h2 class="subtitle has-text-left" style="margin-top: 1rem;">
        Personality traits are strong predictors of human behavior. As LLMs begin to exhibit personality-like tendencies, understanding these traits becomes crucial for trust, safety, and interpretability. We investigate <i>(RQ1)</i> the emergence of self-reported traits (e.g., Big Five, self-regulation) across training stages; <i>(RQ2)</i>  their predictive value for real-world-inspired behavioral tasks (e.g., risk-taking, honesty, sycophancy); and <i>(RQ3)</i>  their controllability through  persona injections. Trait assessments use adapted psychological questionnaires and behavioral probes, with comparisons to human baselines.
        
      </h2>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Personality traits have long been studied as predictors of human behavior. Recent advances in Large Language Models (LLMs) suggest similar patterns may emerge in artificial systems, with advanced LLMs displaying consistent behavioral tendencies resembling human traits like agreeableness and self-regulation. Understanding these patterns is crucial, yet prior work primarily relied on simplified self-reports and heuristic prompting, with little behavioral validation. In this study, we systematically characterize LLM personality across three dimensions: <i>(1)</i> the dynamic emergence and evolution of trait profiles throughout training stages; <i>(2)</i> the predictive validity of self-reported traits in behavioral tasks; and <i>(3)</i> the impact of targeted interventions, such as persona injection, on both self-reports and behavior. Our findings reveal that instructional alignment (e.g., RLHF, instruction tuning) significantly stabilizes trait expression and strengthens trait correlations in ways that mirror human data. However, these self-reported traits do not reliably predict behavior, and observed associations often diverge from human patterns. While persona injection successfully steers self-reports in the intended direction, it exerts little or inconsistent effect on actual behavior. By distinguishing surface-level trait expression from behavioral consistency, our findings challenge assumptions about LLM personality and underscore the need for deeper evaluation in alignment and interpretability.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero teaser" style="padding-top: 2rem;">
  <div class="container is-max-desktop">
    <h2 class="title is-4">
  RQ1 (Origin): 
  <span style="font-size: 0.95em;">
    When and how do human-like traits emerge and evolve across LLM training?
  </span>
</h2>
    <div class="hero-body has-text-centered">
      <img src="static/images/RQ1_updated.png" 
           alt="RQ1 Figure" 
           style="max-width: 100%; height: auto; display: block; margin: 0 auto;" />
      <h2 class="subtitle has-text-left" style="margin-top: 1rem;">
        We compare six open-source base models with their corresponding instruction-tuned versions using standard psychological questionnaires (BFI & SRQ). We find that <i>(a)</i> instruction-aligned models are more open and agreeable but less neurotic than pre-trained models; <i>(b)</i> they show significantly lower variability across five of six traits; and <i>(c)</i> they exhibit stronger, more consistent, and human-aligned associations between personality traits and self-regulation. Together, these results show that <b><i>instructional alignment yields more stable and coherent personality profiles in LLMs when measured through self-report questionnaires.</i></b>

      </h2>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
          <h2 class="title is-4">
  RQ2 (Manifestation): 
  <span style="font-size: 0.95em;">
     Do self-reported traits predict performance in real-world-inspired tasks?
  </span>
</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/heatmap.png" alt="MY ALT TEXT" style="margin-bottom: 1rem;"/>
        <h2 class="subtitle has-text-left">
          We test twelve instruction-tuned models (including SOTA models like GPT-4o) on five behavioral tasks. Using a mixed-effects model, we evaluate the predictive power of self-reported personality traits for downstream tasks and their alignment with human patterns. Each panel shows coefficients for LLM traits predicting behavior across five tasks, broken down by all models, small vs. large models, and by family (LLaMA, Qwen). <b> <i>Most associations are not statistically significant (no *), weak in effect (faint color), or misaligned with human expectations (red).</i></b>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/alignment.png" alt="MY ALT TEXT" style="margin-bottom: 1rem;"/>
        <h2 class="subtitle has-text-left">
          We show the overall percentage of cases where LLM self-reports were directionally aligned with behavioral tasks in accordance with human expectations, grouped by traits, behavioral tasks, and model types. The 50% line represents random behavior (i.e., alignment expected by chance). <b><i>Most self-report-behavior associations hover near chance, with few traits, tasks, or models showing reliable alignment with human patterns.</i></b>
        </h2>
      </div>
  </div>
</div>
</div>
</section>


<section class="hero teaser" style="padding-top: 2rem;">
  <div class="container is-max-desktop">
              <h2 class="title is-4">
  RQ3 (Control): 
  <span style="font-size: 0.95em;">
     How do interventions like persona injection modulate trait profiles and behavior?
  </span>
</h2>
    <div class="hero-body has-text-centered">
      <img src="static/images/RQ3_c.png" 
           alt="RQ1 Figure" 
           style="max-width: 100%; height: auto; display: block; margin: 0 auto;" 
           />
      <h2 class="subtitle has-text-left" style="margin-top: 1rem;">
        We test whether persona injection can steer self-reported traits and behavioral tasks. The figure shows coefficient estimates (95% CI) from logistic regressions predicting persona condition (Agreeableness or Self-Regulation vs. Default) using either six self-reported traits or one behavioral measure (sycophancy or risk-taking). Across three prompting strategies (indicated by color intensity) from established LLM personality research, we find that <b><i>self-reports reliably reflect persona presence, whereas behavioral measures do not—highlighting the limited transfer of persona effects to downstream behavior.</i></b>
      </h2>
    </div>
  </div>
</section>


<section class="hero teaser is-light" style="padding-top: 2rem;">
  <div class="container is-max-desktop">
              <h2 class="title is-4">
  Conclusion: 
  <span style="font-size: 0.95em;">
     Liguistic-Behavioral Dissociation in LLMs.
  </span>
</h2>
    <div class="hero-body has-text-centered">
      <h2 class="subtitle has-text-left" style="margin-top: 1rem;">
        Our results reveal a fundamental dissociation between linguistic self-expression and behavioral
consistency: even state-of-the-art LLMs fail to act in line with their reported traits. Current alignment
methods such as RLHF refine linguistic plausibility without grounding it in behavioral regularity, and
interventions like persona prompts only steer surface-level self-reports. This inconsistency cautions
against treating linguistic coherence as evidence of cognitive depth and raises concerns for real-world
deployment, underscoring the need for different and deeper forms of alignment.
      </h2>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation</h2>
      <pre><code>@misc{han2025personalityillusionrevealingdissociation,
      title={The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs}, 
      author={Pengrui Han and Rafal Kocielnik and Peiyang Song and Ramit Debnath and Dean Mobbs and Anima Anandkumar and R. Michael Alvarez},
      year={2025},
      eprint={2509.03730},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2509.03730}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
